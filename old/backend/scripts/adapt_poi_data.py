import json
import sys
from pathlib import Path
from typing import List, Dict, Any


def extract_tags_from_description(description: str, name: str) -> List[str]:
    """Extract relevant tags from description using keywords"""
    tags = []
    
    keywords_map = {
        "Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ": ["Ñ†Ğ°Ñ€ÑŒ", "Ğ¸Ğ¼Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€", "Ğ²ĞµĞº", "Ğ³Ğ¾Ğ´", "Ğ¿Ğ°Ğ¼ÑÑ‚Ğ½Ğ¸Ğº", "Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹"],
        "Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°": ["Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ", "Ğ±Ğ°ÑˆĞ½Ñ", "Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°", "ĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ñ", "ÑĞ¾Ğ¾Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ"],
        "Ğ¿Ğ°Ğ¼ÑÑ‚Ğ½Ğ¸Ğº": ["Ğ¿Ğ°Ğ¼ÑÑ‚Ğ½Ğ¸Ğº", "Ğ¼Ğ¾Ğ½ÑƒĞ¼ĞµĞ½Ñ‚", "ÑĞºÑƒĞ»ÑŒĞ¿Ñ‚ÑƒÑ€Ğ°", "ÑÑ‚Ğ°Ñ‚ÑƒÑ", "Ğ±ÑÑÑ‚"],
        "Ñ„Ğ¾Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ": ["Ğ²Ğ¸Ğ´", "Ğ¿ĞµĞ¹Ğ·Ğ°Ğ¶", "Ğ¿Ğ°Ğ½Ğ¾Ñ€Ğ°Ğ¼Ğ°", "ĞºÑ€Ğ°ÑĞ¸Ğ²Ğ¾"],
        "Ğ’Ğ¾Ğ»Ğ³Ğ°": ["Ğ²Ğ¾Ğ»Ğ³Ğ°", "Ğ¾ĞºĞ°"],
        "ĞºÑƒĞ»ÑŒÑ‚ÑƒÑ€Ğ°": ["Ğ¿Ğ¸ÑĞ°Ñ‚ĞµĞ»ÑŒ", "Ğ¿Ğ¾ÑÑ‚", "Ñ…ÑƒĞ´Ğ¾Ğ¶Ğ½Ğ¸Ğº", "Ğ°Ñ€Ñ‚Ğ¸ÑÑ‚"],
        "Ğ¸Ğ½Ğ¶ĞµĞ½ĞµÑ€Ğ¸Ñ": ["Ğ¸Ğ½Ğ¶ĞµĞ½ĞµÑ€", "Ñ‚ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ", "ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹"],
        "Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ğ¾": ["Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ğ¾", "ÑĞ²Ğ¾Ğ±Ğ¾Ğ´Ğ½Ñ‹Ğ¹ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿"],
    }
    
    text = (description + " " + name).lower()
    
    for tag, keywords in keywords_map.items():
        if any(keyword in text for keyword in keywords):
            tags.append(tag)
    
    if not tags:
        tags = ["Ğ´Ğ¾ÑÑ‚Ğ¾Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ‡Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ", "Ğ¿Ğ°Ğ¼ÑÑ‚Ğ½Ğ¸Ğº"]
    
    return list(set(tags))[:5]


def infer_social_mode(description: str, category: str) -> str:
    """Infer social mode from description"""
    desc_lower = description.lower()
    
    if "ÑĞµĞ¼ÑŒÑ" in desc_lower or "Ğ´ĞµÑ‚Ğ¸" in desc_lower:
        return "family"
    elif "Ñ€Ğ¾Ğ¼Ğ°Ğ½Ñ‚Ğ¸Ğº" in desc_lower or "Ğ²Ğ»ÑĞ±Ğ»ĞµĞ½Ğ½" in desc_lower:
        return "friends"
    
    if category in ["monument", "viewpoint", "architecture"]:
        return "any"
    
    return "any"


def infer_intensity(category: str, avg_visit_minutes: int) -> str:
    """Infer intensity level from category and visit time"""
    if category in ["monument", "viewpoint"]:
        return "relaxed"
    elif category in ["museum"] and avg_visit_minutes > 60:
        return "medium"
    else:
        return "relaxed"


def adapt_poi(original: Dict[str, Any]) -> Dict[str, Any]:
    """Adapt POI to our format"""
    adapted = {
        "id": original["id"],
        "name": original["name"],
        "lat": original["lat"],
        "lon": original["lon"],
        "category": original["category"],
        "description": original["description"],
        "rating": original.get("rating", 4.0),
        "avg_visit_minutes": original.get("avg_visit_minutes", 30),
    }
    
    if "address" in original:
        adapted["address"] = original["address"]
    
    if original.get("tags") and len(original["tags"]) > 0:
        adapted["tags"] = original["tags"]
    else:
        adapted["tags"] = extract_tags_from_description(
            original["description"], 
            original["name"]
        )
    
    adapted["social_mode"] = infer_social_mode(
        original["description"], 
        original["category"]
    )
    
    adapted["intensity_level"] = infer_intensity(
        original["category"],
        original.get("avg_visit_minutes", 30)
    )
    
    if "monument" in original["name"].lower() or original["category"] == "monument":
        adapted["photo_tip"] = "Ğ¡Ğ½Ğ¸Ğ¼Ğ°Ğ¹Ñ‚Ğµ Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ñ€Ğ°ĞºÑƒÑ€ÑĞ¾Ğ², Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ½Ñ‹Ğ¹ Ğ¿ĞµÑ€ĞµĞ´Ğ½Ğ¸Ğ¹ Ğ¿Ğ»Ğ°Ğ½"
    
    desc = original["description"].lower()
    if "Ğ½Ğ°Ğ±ĞµÑ€ĞµĞ¶Ğ½" in desc or "Ñ€ĞµĞºĞ°" in desc or "Ğ²Ğ¾Ğ»Ğ³Ğ°" in desc or "Ğ¾ĞºĞ°" in desc:
        adapted["local_tip"] = "Ğ›ÑƒÑ‡ÑˆĞµ Ğ²ÑĞµĞ³Ğ¾ Ğ¿Ğ¾ÑĞµÑ‰Ğ°Ñ‚ÑŒ Ğ½Ğ° Ğ·Ğ°ĞºĞ°Ñ‚Ğµ Ğ¸Ğ»Ğ¸ Ñ€Ğ°Ğ½Ğ¾ ÑƒÑ‚Ñ€Ğ¾Ğ¼ Ğ´Ğ»Ñ Ğ°Ñ‚Ğ¼Ğ¾ÑÑ„ĞµÑ€Ğ½Ñ‹Ñ… Ñ„Ğ¾Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ğ¹"
    elif "Ğ¿Ğ°Ğ¼ÑÑ‚Ğ½Ğ¸Ğº" in desc:
        adapted["local_tip"] = "ĞœĞ¾Ğ¶Ğ½Ğ¾ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ñ‚ÑŒ Ñ Ğ¿Ñ€Ğ¾Ğ³ÑƒĞ»ĞºĞ¾Ğ¹ Ğ¿Ğ¾ Ğ¾ĞºÑ€ĞµÑÑ‚Ğ½Ğ¾ÑÑ‚ÑĞ¼"
    
    return adapted


def adapt_poi_dataset(input_path: Path, output_path: Path) -> None:
    """Adapt entire POI dataset"""
    print(f"ğŸ“‚ Reading: {input_path}")
    
    with open(input_path, "r", encoding="utf-8") as f:
        original_data = json.load(f)
    
    print(f"ğŸ“Š Found {len(original_data)} POIs")
    
    adapted_data = []
    categories = {}
    
    for poi in original_data:
        adapted_poi = adapt_poi(poi)
        adapted_data.append(adapted_poi)
        
        cat = adapted_poi["category"]
        categories[cat] = categories.get(cat, 0) + 1
    
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(adapted_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… Adapted {len(adapted_data)} POIs")
    print(f"ğŸ’¾ Saved to: {output_path}")
    
    print(f"\nğŸ“Š Categories:")
    for cat, count in sorted(categories.items(), key=lambda x: -x[1]):
        print(f"  {cat:15s}: {count}")
    
    with_tags = sum(1 for p in adapted_data if len(p.get("tags", [])) > 0)
    with_tips = sum(1 for p in adapted_data if p.get("local_tip"))
    with_photos = sum(1 for p in adapted_data if p.get("photo_tip"))
    
    print(f"\nğŸ“ˆ Quality metrics:")
    print(f"  With tags: {with_tags}/{len(adapted_data)} ({with_tags/len(adapted_data)*100:.1f}%)")
    print(f"  With local tips: {with_tips}/{len(adapted_data)} ({with_tips/len(adapted_data)*100:.1f}%)")
    print(f"  With photo tips: {with_photos}/{len(adapted_data)} ({with_photos/len(adapted_data)*100:.1f}%)")
    
    print(f"\nğŸ’¡ Recommendations:")
    if with_tags < len(adapted_data):
        print(f"  âš ï¸  {len(adapted_data) - with_tags} POIs need better tags")
    if with_tips < len(adapted_data) * 0.5:
        print(f"  âš ï¸  Consider adding more local tips (only {with_tips/len(adapted_data)*100:.1f}%)")


def main():
    if len(sys.argv) < 2:
        print("Usage: python adapt_poi_data.py <input.json> [output.json]")
        print("\nExample:")
        print("  python adapt_poi_data.py raw_pois.json data/poi_adapted.json")
        sys.exit(1)
    
    input_path = Path(sys.argv[1])
    
    if len(sys.argv) >= 3:
        output_path = Path(sys.argv[2])
    else:
        output_path = input_path.parent / f"{input_path.stem}_adapted.json"
    
    if not input_path.exists():
        print(f"âŒ Error: File not found: {input_path}")
        sys.exit(1)
    
    adapt_poi_dataset(input_path, output_path)
    
    print("\nâœ… Adaptation completed!")
    print(f"\nNext steps:")
    print(f"1. Review: {output_path}")
    print(f"2. Validate: python scripts/validate_pois.py {output_path}")
    print(f"3. Load: docker compose exec backend poetry run python scripts/load_pois.py")


if __name__ == "__main__":
    main()